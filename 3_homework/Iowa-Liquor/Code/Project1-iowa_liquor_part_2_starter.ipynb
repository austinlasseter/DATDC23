{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 - Iowa Liquor \n",
    "\n",
    "You are a data scientist in residence at the Iowa State tax board. The Iowa State legislature is considering changes in the liquor tax rates and wants a report of current liquor sales by county and projections for the rest of the year. \n",
    "\n",
    "Your task is as follows:\n",
    "\n",
    "* Calculate the yearly liquor sales for each store using the provided data. You can add up the transactions for each year, and store sales in 2015 specifically will be used later as your target variable.\n",
    "* Use the data from 2015 to make a linear model using as many variables as you find useful to predict the yearly sales of all stores. You must use the sales from Jan to March as one of your variables.\n",
    "* Use your model for 2015 to estimate total sales in 2016, extrapolating from the sales so far for Jan-March of 2016.\n",
    "* Report your findings, including any projected increase or decrease in total sales (over the entire state) for the tax committee of the Iowa legislature.\n",
    "* Use cross-validation to check how your model predicts to held out data compared to the model metrics on the full dataset.\n",
    "* Fit your model(s) using one or both of the regularization tactics covered. Explain whether the regularized or the non-regularized model performed better and what the selected regression(s) are doing.\n",
    "\n",
    "\n",
    "\n",
    "# Part 2\n",
    "\n",
    "### Feature Engineering, Model Building, and Tuning\n",
    "\n",
    "In Part 2 of this two-part project, you will use the insights gained from your Exploratory Data Analysis (EDA) to build a linear regression model predicting end-of-year total sales using Q1 data. You will use 2015 data to train and tune your model, then make final predictions using Q1 2016 data to make your best estimates for end of year 2016!\n",
    "\n",
    "### Requirements:\n",
    "\n",
    "\n",
    "**Mine the data**\n",
    "- Create necessary derived columns from the data\n",
    "- Format, clean, slice, and combine the data in Python\n",
    "\n",
    "**Build a data model**\n",
    "- Complete linear regressions using scikit-learn or statsmodels and interpret your findings\n",
    "- Calculate and plot predicted probabilities and/or present tables of results\n",
    "- Describe the bias-variance tradeoff of your model and errors metrics\n",
    "- Evaluate model fit by using loss functions, including mean absolute error, mean squared error, and root mean squared error, or r-squared\n",
    "\n",
    "**Present the results**\n",
    "- Create a Jupyter Notebook hosted on GitHub that provides a dataset overview with visualizations, statistical analysis, data cleaning methodologies, and models\n",
    "- Create a write-up on the interpretation of findings including an executive summary with conclusions and next steps\n",
    "\n",
    "***Bonus!:***\n",
    "- Handle outliers, use regularization (Ridge & Lasso regressions)\n",
    "- Brainstorm ways to improve your analysis; for example:\n",
    " - Add additional breakdowns and models, e.g. by month.\n",
    " - Recommend additional data that might improve your models\n",
    " - Can you think of other uses for the dataset? E.g healthcare / disease estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.path.isfile('../Assets/Iowa_Liquor_sample.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Clean data:\n",
    "\n",
    "This time, we've cleaned the data set and column names for you; however we have not touched missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import, convert 'Date' col to datetime\n",
    "liquor=pd.read_csv('../Assets/Iowa_Liquor_sample.csv',parse_dates=['Date'],infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format column names\n",
    "import re\n",
    "\n",
    "liquor.columns = [re.sub(\"[^a-zA-Z]+\", \"\", x) for x in liquor.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove '$' in values and convert to numeric\n",
    "adjust_cols = ['StateBottleCost','StateBottleRetail','SaleDollars']\n",
    "\n",
    "for col in adjust_cols:\n",
    "    liquor[col] = pd.to_numeric(liquor[col].str.replace('$',''),errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Values\n",
    "\n",
    "Handle null values as you see fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# liquor = liquor.dropna()\n",
    "# liquor.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Split Data to Create a features and targets\n",
    "\n",
    "The goal of this project is to predict **total year-end 2015 sales for each store** using **first-quarter 2015 data**\n",
    "\n",
    "Our data is currently formatted as total purchases for each product per day per store for every day in the year. We will need to group our data by store when we perform our aggregations.\n",
    "\n",
    "In order to accomplish our goal, we need two sets of data:\n",
    "* Total full-year  sales for each store in 2015 (our target / y)\n",
    "* Data from Q1 2015 (will become our features / X)\n",
    "\n",
    "Create two dataframes, 'liquor2015_fy' and 'liquor2015_q1'\n",
    "\n",
    "'liquor2015_fy' should contain only store numbers and the full year sales for that store\n",
    "\n",
    "'liquor2015_q1' should contain all your features, but only for Q1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only 2015:\n",
    "# hint: liquor.Date.dt._______\n",
    "\n",
    "liquor2015 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum of sales for each store in 2015 by grouping the full year data\n",
    "# hint: what columns do you need? what is your aggregating function? \n",
    "liquor2015_fy ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter to just Q1 data: \n",
    "# hint: df[df.Date.dt.___ == __]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "Using the insight your gained into your dataset while perfomorming *exploratory data analysis* in Part 1 of the project, aggregate the liquor2015_q1 data frame to create cross-sectional features from our longitudinal data.\n",
    "\n",
    "\n",
    "[Aggregation functions in pandas](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.DataFrameGroupBy.agg.html)\n",
    "\n",
    "In addition to aggregation, you may chose to create columns to more advanced measures of the data, such as sales for a particular product or category, measures of profitbility, daily or weekly sales statistics, etc.\n",
    "\n",
    "Combine your aggregations and other engineered features into a dataframe called 'liquor2015_q1_features'\n",
    "\n",
    "*At a minimum, you will need to aggreate your features by Store in order to procede*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# liquor2015_q1.groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataframe of your Q1 features\n",
    "liquor2015_q1_features = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Q1 Features with Full Year Target\n",
    "\n",
    "Now that you've created a set of features using the Q1 data, we much combine it wil the full-year data so that our Xs (features) are matched up to their coresponding y's (targets).\n",
    "\n",
    "Pandas' 'merge' function allows us to combine two dataframes, using SQL-like joins.\n",
    "\n",
    "[Pandas Merge/Join Documentation](https://pandas.pydata.org/pandas-docs/stable/merging.html#database-style-dataframe-joining-merging)\n",
    "\n",
    "We will create a new dataframe, called 'liquor2015_combined' by merging our 'liquor2015_fy' and 'liquor2015_q1_features' dataframes on Store Number - giving us a dataframe which in each row has the Q1 features you've developed for each store, and the year-end total sales for that store.\n",
    "\n",
    "#### In pandas, merge can take two forms:\n",
    "\n",
    "pd.merge(left_dataframe,right_dataframe, \\*\\*args)\n",
    "\n",
    "*or*\n",
    "\n",
    "left_dataframe.merge(right_dataframe,\\*\\*args)\n",
    "\n",
    "Both of these return the merged dataframe. For arguments, you will need to chose which column(s) from your right and left dataframe you're merging on.\n",
    "\n",
    "Args:\n",
    "* left: your left-dataframe\n",
    "* right: your right-dataframe\n",
    "* on= : if your dataframes have a common column name that you're merging on, use this arg\n",
    "* left_on= / right_on= : if your dataframes do not have a common column name, you can specify the names\n",
    "* left_index= / right_index= : these are boolean (True/False) flags for whether to use the dataframe's index as the merging column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liquor2015_combined = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "As we build our model, we will use cross-validation techniques to help navigate the bias/variance tradeoff, with a goal of producing the best model which will generalize to new data. \n",
    "\n",
    "![crossval](../Assets/validation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Hold Out / Testing Data\n",
    "\n",
    "In order to evaluate our final model performance, we will seperate out a small amount of data which will will not touch while train and test our model (labeled in red as \"Testing Data\" in the image above). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data,holdout = train_test_split(liquor2015_combined,shuffle=True,test_size=0.10,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Kfolds\n",
    "\n",
    "With our holdout set removed, we can set up **Kfolds** cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of folds you wish to train\n",
    "folds = \n",
    "\n",
    "# Number of rows in your dataframe\n",
    "n = training_data.shape[0]\n",
    "\n",
    "kf = KFold(<FILL IN ARGS>,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building - Linear Regression\n",
    "\n",
    "With feature prepared and a cross-validation framework in place, train and tune a linear regressor to predict year-end sales using your q1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#select your feature column names\n",
    "\n",
    "feature_cols = [<FEATURES>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your X (features) and y (target)\n",
    "# hint - make sure your y is not in your X!\n",
    "\n",
    "X = training_data[feature_cols]\n",
    "y = training_data[<TARGET>]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the kfolds iterator to **train** and **evaluate** your model, using Mean Squared Error (MSE) as your evluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a blank list to store fold scores\n",
    "scores =\n",
    "# Fill-in the kfolds-loop:\n",
    "\n",
    "for train,test in kf:\n",
    "    # Set up your training and testing sets\n",
    "    x_train = X.iloc[train]\n",
    "#     x_test =\n",
    "    y_train = y.iloc[train]\n",
    "#     y_true =\n",
    "    \n",
    "    # Fit your model on your training x and training y\n",
    "    lr.fit(x_train,y_train)\n",
    "    \n",
    "    # Make Predictions\n",
    "    y_preds = \n",
    "    \n",
    "    # Score your predictions vs. your true values using mean_squared_error\n",
    "    fold_score = mean_squared_error()\n",
    "    \n",
    "    # Append your score \n",
    "    scores.append()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# View your fold scores, and calculate the mean score across your folds\n",
    "# np.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficients and Intercept\n",
    "\n",
    "View the coefficients of your model - what do the coefficients tell you about the relationships between your features and your target?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(feature_cols,lr.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Your Model\n",
    "\n",
    "So far, you've trained a basic linear model and evaluated it using Mean Squared Error. Use the same process as above to evaluate your model using: Mean Absolute Error (MAE), Root Mean Squared Error (RMSE) and calculate the R2 score of your predictions.\n",
    "\n",
    "Try some of the parameters available for your linear model, and different sets of features to find a model that you feel will **perform best on new, out of sample data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols_new = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = training_data[feature_cols_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use K-Folds cross validation to train your model\n",
    "# Evaluate your model using MAE, MSE, RMSE and R2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compare your MAE, MSE, RMSE and R2 values for your folds; describe anything that stands out.\n",
    "# How do your metrics respond to different feature sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate your coefficients and your intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test against your hold-out set\n",
    "\n",
    "Before you build your model, you set aside some of your data for testing. Your model has never trained against these data points or been evaluated agaist these points.\n",
    "\n",
    "Use **ALL** of your training data to train, then test your model against your holdout set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pick your best set of feature columns\n",
    "features = [<FEATURES>]\n",
    "\n",
    "X_train = training_data[features]\n",
    "y_train = \n",
    "\n",
    "x_holdout = holdout[features]\n",
    "y_holdout = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit your model using all of your training data\n",
    "lr.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions using your holdout set (x_holdout)\n",
    "holdout_preds ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# score your model using MAE, MSE, RMSE, and R2\n",
    "# hint: what is y_test and what is your y_true?\n",
    "\n",
    "MAE_score =\n",
    "MSE_score =\n",
    "RMSE_score =\n",
    "R2_score =\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print your scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a scatter plot of your predicted values vs. their true values\n",
    "# Describe anything you observe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate your residuals (prediction - actual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a histogram of your residuals. Describe anything you observe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Predictions\n",
    "\n",
    "You've created a model that predicts 2015 year end sales based on Q1 2015 data. \n",
    "\n",
    "In the data source, we have included data for Q1 of 2016. Apply your feature engineering process to the 2016 Q1 data, then use your trained 2015 model to predict the 2016 year end values for those stores.\n",
    "\n",
    "Note: you do not have the 2016 year end values to evaluate against.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "Perform the same aggregation and feature creation you used on 2015 data on the 2016 data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# liquour[liquor.Date.dt.Year == 2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions\n",
    "\n",
    "Once you have your 2016 features, use your trained 2015 model on the 2016 Q1 data to get your predictions for 2016\n",
    "\n",
    "Do not retrain a model on the 2016 data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show your 2016 year-end prediction for each store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation:\n",
    "\n",
    "Do your best to answer the following questions:\n",
    "\n",
    "* What was the best set of features you found for your model?\n",
    "* Describe the relationships between your features and your target\n",
    "* How did your model perform in the training phase? Against the holdout set? \n",
    "* Did it perform better or worse against the holdout set?\n",
    "\n",
    "Finally:\n",
    "* Write a short description of your analysis, describing the process you went through and your confidence in your model's predictive ability\n",
    "* Include any data, or visualizations you feel would help support your findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus - Regularization & Grid Search\n",
    "\n",
    "As a bonus, experiment with the effect of Lasso (L1) and Ridge (L2) regularization on your linear model. Use GridSearch to tune your additional parameters.\n",
    "\n",
    "See [gridseach 'scoring' options](http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) for a list of scoring function strings recognized by GridSeach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate models\n",
    "lr_ridge = \n",
    "lr_lasso = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your post-holdout training data, so you can evaluate on the holdout later\n",
    "X = \n",
    "y = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expirement with values of Alpha, scoring functions, and L1/L2 regulatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'alpha':[0.2,1.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(<model>,params,cv=5,scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gridsearch incorporates k-folds validation\n",
    "# You do not have to create training/testing splits\n",
    "gs.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all permutation scores\n",
    "gs.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use the best set of parameters\n",
    "lr_best = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try the best estimator on your holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation:\n",
    "\n",
    "Did regularization improve your model? What was the impact of regularization on your features? Did regularization make any features stand out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
