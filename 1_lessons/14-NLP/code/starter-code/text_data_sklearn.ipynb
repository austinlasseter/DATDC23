{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Text Data and Naive Bayes in scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "**Working with text data**\n",
    "\n",
    "- Representing text as data\n",
    "- Reading SMS data\n",
    "- Vectorizing SMS data\n",
    "- Examining the tokens and their counts\n",
    "- Bonus: Calculating the \"spamminess\" of each token\n",
    "\n",
    "**Naive Bayes classification**\n",
    "\n",
    "- Building a Naive Bayes model\n",
    "- Comparing Naive Bayes with logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Representing text as data\n",
    "\n",
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> Text Analysis is a major application field for machine learning algorithms. However the raw data, a sequence of symbols cannot be fed directly to the algorithms themselves as most of them expect **numerical feature vectors with a fixed size** rather than the **raw text documents with variable length**.\n",
    "\n",
    "We will use [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to \"convert text into a matrix of token counts\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start with a simple example\n",
    "simple_train = ['call you tonight', 'Call me a cab', 'please call me... PLEASE!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'cab', u'call', u'me', u'please', u'tonight', u'you']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn the 'vocabulary' of the training data\n",
    "vect = CountVectorizer()\n",
    "vect.fit(simple_train)\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x6 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 9 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform training data into a 'document-term matrix'\n",
    "simple_train_dtm = vect.transform(simple_train)\n",
    "simple_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 3)\t2\n"
     ]
    }
   ],
   "source": [
    "# print the sparse matrix\n",
    "print(simple_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 2, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert sparse matrix to a dense matrix\n",
    "simple_train_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   0       0        1    1\n",
       "1    1     1   1       0        0    0\n",
       "2    0     1   1       2        0    0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "import pandas as pd\n",
    "pd.DataFrame(simple_train_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a document-term matrix on your own\n",
    "simple_train = [\"Sorry, Ill call later\", \n",
    "                \"K Did you call me just now ah\", \n",
    "                \"I call you later,no signal. If urgnt, sms me\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete your work below\n",
    "vect = CountVectorizer()\n",
    "vect_data = vect.fit_transform(simple_train)\n",
    "vect_data = vect_data.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ah</th>\n",
       "      <th>call</th>\n",
       "      <th>did</th>\n",
       "      <th>if</th>\n",
       "      <th>ill</th>\n",
       "      <th>just</th>\n",
       "      <th>later</th>\n",
       "      <th>me</th>\n",
       "      <th>no</th>\n",
       "      <th>now</th>\n",
       "      <th>signal</th>\n",
       "      <th>sms</th>\n",
       "      <th>sorry</th>\n",
       "      <th>urgnt</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ah  call  did  if  ill  just  later  me  no  now  signal  sms  sorry  \\\n",
       "0   0     1    0   0    1     0      1   0   0    0       0    0      1   \n",
       "1   1     1    1   0    0     1      0   1   0    1       0    0      0   \n",
       "2   0     1    0   1    0     0      1   1   1    0       1    1      0   \n",
       "\n",
       "   urgnt  you  \n",
       "0      0    0  \n",
       "1      0    1  \n",
       "2      1    1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=vect_data,columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> In this scheme, features and samples are defined as follows:\n",
    "\n",
    "> - Each individual token occurrence frequency (normalized or not) is treated as a **feature**.\n",
    "> - The vector of all the token frequencies for a given document is considered a multivariate **sample**.\n",
    "\n",
    "> A **corpus of documents** can thus be represented by a matrix with **one row per document** and **one column per token** (e.g. word) occurring in the corpus.\n",
    "\n",
    "> We call **vectorization** the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the **Bag of Words** or \"Bag of n-grams\" representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data into a document-term matrix (using existing vocabulary)\n",
    "simple_test = [\"please don't call me\"]\n",
    "simple_test_dtm = vect.transform(simple_test)\n",
    "simple_test_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ah</th>\n",
       "      <th>call</th>\n",
       "      <th>did</th>\n",
       "      <th>if</th>\n",
       "      <th>ill</th>\n",
       "      <th>just</th>\n",
       "      <th>later</th>\n",
       "      <th>me</th>\n",
       "      <th>no</th>\n",
       "      <th>now</th>\n",
       "      <th>signal</th>\n",
       "      <th>sms</th>\n",
       "      <th>sorry</th>\n",
       "      <th>urgnt</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ah  call  did  if  ill  just  later  me  no  now  signal  sms  sorry  \\\n",
       "0   0     1    0   0    0     0      0   1   0    0       0    0      0   \n",
       "\n",
       "   urgnt  you  \n",
       "0      0    0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(simple_test_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "\n",
    "- `vect.fit(train)` learns the vocabulary of the training data\n",
    "- `vect.transform(train)` uses the fitted vocabulary to build a document-term matrix from the training data\n",
    "- `vect.transform(test)` uses the fitted vocabulary to build a document-term matrix from the testing data (and ignores tokens it hasn't seen before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Reading SMS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    }
   ],
   "source": [
    "# read tab-separated file\n",
    "url = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/sms.tsv'\n",
    "col_names = ['label', 'message']\n",
    "sms = pd.read_table(url, sep='\\t', header=None, names=col_names)\n",
    "print(sms.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spam</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ham</td>\n",
       "      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ham</td>\n",
       "      <td>Fine if thats the way u feel. Thats the way ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spam</td>\n",
       "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5   spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6    ham  Even my brother is not like to speak with me. ...\n",
       "7    ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8   spam  WINNER!! As a valued network customer you have...\n",
       "9   spam  Had your mobile 11 months or more? U R entitle...\n",
       "10   ham  I'm gonna be home soon and i don't want to tal...\n",
       "11  spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
       "12  spam  URGENT! You have won a 1 week FREE membership ...\n",
       "13   ham  I've been searching for the right words to tha...\n",
       "14   ham                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
       "15  spam  XXXMobileMovieClub: To use your credit, click ...\n",
       "16   ham                         Oh k...i'm watching here:)\n",
       "17   ham  Eh u remember how 2 spell his name... Yes i di...\n",
       "18   ham  Fine if thats the way u feel. Thats the way ...\n",
       "19  spam  England v Macedonia - dont miss the goals/team..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert label to a numeric variable\n",
    "sms['label'] = sms.label.map({'ham':0, 'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = sms.message\n",
    "y = sms.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4179L,)\n",
      "(1393L,)\n"
     ]
    }
   ],
   "source": [
    "# split into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Vectorizing SMS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate the vectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn training data vocabulary, then create document-term matrix\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative: combine fit and transform into a single step\n",
    "X_train_dtm = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Examining the tokens and their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store token names\n",
    "tokens = vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'00',\n",
       " u'000',\n",
       " u'008704050406',\n",
       " u'0121',\n",
       " u'01223585236',\n",
       " u'01223585334',\n",
       " u'0125698789',\n",
       " u'02',\n",
       " u'0207',\n",
       " u'02072069400',\n",
       " u'02073162414',\n",
       " u'02085076972',\n",
       " u'021',\n",
       " u'03',\n",
       " u'04',\n",
       " u'0430',\n",
       " u'05',\n",
       " u'050703',\n",
       " u'0578',\n",
       " u'06',\n",
       " u'07',\n",
       " u'07008009200',\n",
       " u'07090201529',\n",
       " u'07090298926',\n",
       " u'07123456789',\n",
       " u'07732584351',\n",
       " u'07734396839',\n",
       " u'07742676969',\n",
       " u'0776xxxxxxx',\n",
       " u'07781482378',\n",
       " u'07786200117',\n",
       " u'078',\n",
       " u'07801543489',\n",
       " u'07808',\n",
       " u'07808247860',\n",
       " u'07808726822',\n",
       " u'07815296484',\n",
       " u'07821230901',\n",
       " u'07880867867',\n",
       " u'0789xxxxxxx',\n",
       " u'07946746291',\n",
       " u'0796xxxxxx',\n",
       " u'07973788240',\n",
       " u'07xxxxxxxxx',\n",
       " u'08',\n",
       " u'0800',\n",
       " u'08000407165',\n",
       " u'08000776320',\n",
       " u'08000839402',\n",
       " u'08000930705']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 50 tokens\n",
    "tokens[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'yer',\n",
       " u'yes',\n",
       " u'yest',\n",
       " u'yesterday',\n",
       " u'yet',\n",
       " u'yetunde',\n",
       " u'yijue',\n",
       " u'ym',\n",
       " u'ymca',\n",
       " u'yo',\n",
       " u'yoga',\n",
       " u'yogasana',\n",
       " u'yor',\n",
       " u'yorge',\n",
       " u'you',\n",
       " u'youdoing',\n",
       " u'youi',\n",
       " u'youphone',\n",
       " u'your',\n",
       " u'youre',\n",
       " u'yourjob',\n",
       " u'yours',\n",
       " u'yourself',\n",
       " u'youwanna',\n",
       " u'yowifes',\n",
       " u'yoyyooo',\n",
       " u'yr',\n",
       " u'yrs',\n",
       " u'ything',\n",
       " u'yummmm',\n",
       " u'yummy',\n",
       " u'yun',\n",
       " u'yunny',\n",
       " u'yuo',\n",
       " u'yuou',\n",
       " u'yup',\n",
       " u'zac',\n",
       " u'zaher',\n",
       " u'zealand',\n",
       " u'zebra',\n",
       " u'zed',\n",
       " u'zeros',\n",
       " u'zhong',\n",
       " u'zindgi',\n",
       " u'zoe',\n",
       " u'zoom',\n",
       " u'zouk',\n",
       " u'zyada',\n",
       " u'\\xe8n',\n",
       " u'\\u3028ud']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last 50 tokens\n",
    "tokens[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7456"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view X_train_dtm as a dense matrix\n",
    "X_train_dtm = X_train_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 23,  2, ...,  1,  1,  1], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count how many times EACH token appears across ALL messages in X_train_dtm\n",
    "import numpy as np\n",
    "\n",
    "np.sum(X_train_dtm, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 23,  2, ...,  1,  1,  1], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(X_train_dtm.toarray(),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>008704050406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>01223585236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>01223585334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0125698789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>02072069400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>02073162414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>02085076972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>050703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>07008009200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>07090201529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>07090298926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>07123456789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>07732584351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>07734396839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>07742676969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>0776xxxxxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>07781482378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7426</th>\n",
       "      <td>1</td>\n",
       "      <td>yourjob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7427</th>\n",
       "      <td>16</td>\n",
       "      <td>yours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7428</th>\n",
       "      <td>14</td>\n",
       "      <td>yourself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7429</th>\n",
       "      <td>1</td>\n",
       "      <td>youwanna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7430</th>\n",
       "      <td>1</td>\n",
       "      <td>yowifes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7431</th>\n",
       "      <td>1</td>\n",
       "      <td>yoyyooo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7432</th>\n",
       "      <td>11</td>\n",
       "      <td>yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7433</th>\n",
       "      <td>6</td>\n",
       "      <td>yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7434</th>\n",
       "      <td>1</td>\n",
       "      <td>ything</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7435</th>\n",
       "      <td>1</td>\n",
       "      <td>yummmm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7436</th>\n",
       "      <td>3</td>\n",
       "      <td>yummy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7437</th>\n",
       "      <td>2</td>\n",
       "      <td>yun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7438</th>\n",
       "      <td>2</td>\n",
       "      <td>yunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7439</th>\n",
       "      <td>4</td>\n",
       "      <td>yuo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7440</th>\n",
       "      <td>1</td>\n",
       "      <td>yuou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7441</th>\n",
       "      <td>33</td>\n",
       "      <td>yup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7442</th>\n",
       "      <td>1</td>\n",
       "      <td>zac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7443</th>\n",
       "      <td>1</td>\n",
       "      <td>zaher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7444</th>\n",
       "      <td>1</td>\n",
       "      <td>zealand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7445</th>\n",
       "      <td>1</td>\n",
       "      <td>zebra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7446</th>\n",
       "      <td>6</td>\n",
       "      <td>zed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7447</th>\n",
       "      <td>1</td>\n",
       "      <td>zeros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7448</th>\n",
       "      <td>1</td>\n",
       "      <td>zhong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7449</th>\n",
       "      <td>2</td>\n",
       "      <td>zindgi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7450</th>\n",
       "      <td>2</td>\n",
       "      <td>zoe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7451</th>\n",
       "      <td>1</td>\n",
       "      <td>zoom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7452</th>\n",
       "      <td>1</td>\n",
       "      <td>zouk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7453</th>\n",
       "      <td>1</td>\n",
       "      <td>zyada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7454</th>\n",
       "      <td>1</td>\n",
       "      <td>èn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7455</th>\n",
       "      <td>1</td>\n",
       "      <td>〨ud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7456 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Count         Token\n",
       "0         5            00\n",
       "1        23           000\n",
       "2         2  008704050406\n",
       "3         1          0121\n",
       "4         1   01223585236\n",
       "5         2   01223585334\n",
       "6         1    0125698789\n",
       "7         4            02\n",
       "8         3          0207\n",
       "9         1   02072069400\n",
       "10        2   02073162414\n",
       "11        1   02085076972\n",
       "12        2           021\n",
       "13        6            03\n",
       "14        9            04\n",
       "15        1          0430\n",
       "16        1            05\n",
       "17        1        050703\n",
       "18        1          0578\n",
       "19        3            06\n",
       "20        2            07\n",
       "21        1   07008009200\n",
       "22        1   07090201529\n",
       "23        1   07090298926\n",
       "24        1   07123456789\n",
       "25        1   07732584351\n",
       "26        2   07734396839\n",
       "27        2   07742676969\n",
       "28        2   0776xxxxxxx\n",
       "29        1   07781482378\n",
       "...     ...           ...\n",
       "7426      1       yourjob\n",
       "7427     16         yours\n",
       "7428     14      yourself\n",
       "7429      1      youwanna\n",
       "7430      1       yowifes\n",
       "7431      1       yoyyooo\n",
       "7432     11            yr\n",
       "7433      6           yrs\n",
       "7434      1        ything\n",
       "7435      1        yummmm\n",
       "7436      3         yummy\n",
       "7437      2           yun\n",
       "7438      2         yunny\n",
       "7439      4           yuo\n",
       "7440      1          yuou\n",
       "7441     33           yup\n",
       "7442      1           zac\n",
       "7443      1         zaher\n",
       "7444      1       zealand\n",
       "7445      1         zebra\n",
       "7446      6           zed\n",
       "7447      1         zeros\n",
       "7448      1         zhong\n",
       "7449      2        zindgi\n",
       "7450      2           zoe\n",
       "7451      1          zoom\n",
       "7452      1          zouk\n",
       "7453      1         zyada\n",
       "7454      1            èn\n",
       "7455      1           〨ud\n",
       "\n",
       "[7456 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame of tokens with their counts\n",
    "pd.DataFrame({\"Count\":np.sum(X_train_dtm.toarray(),axis=0),\"Token\":tokens})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Calculating the \"spamminess\" of each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create separate DataFrames for ham and spam\n",
    "sms_ham = sms[sms.label==0]\n",
    "sms_spam = sms[sms.label==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn the vocabulary of ALL messages and save it\n",
    "cv = CountVectorizer().fit(sms.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create document-term matrices for ham and spam\n",
    "ham_dtm = cv.transform(sms_ham.message)\n",
    "spam_dtm = cv.transform(sms_spam.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count how many times EACH token appears across ALL ham messages\n",
    "ham_counts = np.sum(ham_dtm.toarray(),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count how many times EACH token appears across ALL spam messages\n",
    "spam_counts = np.sum(spam_dtm.toarray(),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a DataFrame of tokens with their separate ham and spam counts\n",
    "token_counts = pd.DataFrame({\"Token\":cv.get_feature_names(),\"Ham\":ham_counts,\"Spam\":spam_counts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add one to ham and spam counts to avoid dividing by zero (in the step that follows)\n",
    "token_counts['Ham'] = token_counts.Ham + 1\n",
    "token_counts['Spam'] = token_counts.Spam + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate ratio of spam-to-ham for each token\n",
    "token_counts['spam_ratio'] = token_counts.Spam / token_counts.Ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jtate\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ham</th>\n",
       "      <th>Spam</th>\n",
       "      <th>Token</th>\n",
       "      <th>spam_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>claim</td>\n",
       "      <td>114.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6113</th>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>prize</td>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>150p</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7837</th>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>tone</td>\n",
       "      <td>61.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>18</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3688</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>guaranteed</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>500</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2371</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>cs</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>1000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>awarded</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8016</th>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>uk</td>\n",
       "      <td>37.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>150ppm</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6525</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>ringtone</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8596</th>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>www</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>collection</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>entry</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>16</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7838</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>tones</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>5000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5117</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>mob</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8375</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>weekly</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>10p</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8153</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>valid</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>800</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5297</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>national</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>bonus</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>8007</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6619</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>sae</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8248</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>vouchers</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925</th>\n",
       "      <td>166</td>\n",
       "      <td>3</td>\n",
       "      <td>home</td>\n",
       "      <td>0.018072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2815</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>dun</td>\n",
       "      <td>0.017857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5533</th>\n",
       "      <td>115</td>\n",
       "      <td>2</td>\n",
       "      <td>oh</td>\n",
       "      <td>0.017391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>116</td>\n",
       "      <td>2</td>\n",
       "      <td>much</td>\n",
       "      <td>0.017241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5254</th>\n",
       "      <td>755</td>\n",
       "      <td>13</td>\n",
       "      <td>my</td>\n",
       "      <td>0.017219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>always</td>\n",
       "      <td>0.016949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7001</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>sleep</td>\n",
       "      <td>0.016949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3595</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>gonna</td>\n",
       "      <td>0.016949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3171</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>feel</td>\n",
       "      <td>0.015873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8394</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>went</td>\n",
       "      <td>0.015873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5371</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>nice</td>\n",
       "      <td>0.015873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3690</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>gud</td>\n",
       "      <td>0.014706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7099</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>something</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7463</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>sure</td>\n",
       "      <td>0.013889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4724</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>lol</td>\n",
       "      <td>0.013333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>anything</td>\n",
       "      <td>0.012987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2289</th>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>cos</td>\n",
       "      <td>0.012987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>231</td>\n",
       "      <td>3</td>\n",
       "      <td>come</td>\n",
       "      <td>0.012987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>morning</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>doing</td>\n",
       "      <td>0.011236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>amp</td>\n",
       "      <td>0.011236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>ask</td>\n",
       "      <td>0.011111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6626</th>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>said</td>\n",
       "      <td>0.011111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4550</th>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>later</td>\n",
       "      <td>0.007353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2428</th>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>da</td>\n",
       "      <td>0.006623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4747</th>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>lor</td>\n",
       "      <td>0.006135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6843</th>\n",
       "      <td>168</td>\n",
       "      <td>1</td>\n",
       "      <td>she</td>\n",
       "      <td>0.005952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3805</th>\n",
       "      <td>232</td>\n",
       "      <td>1</td>\n",
       "      <td>he</td>\n",
       "      <td>0.004310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4793</th>\n",
       "      <td>317</td>\n",
       "      <td>1</td>\n",
       "      <td>lt</td>\n",
       "      <td>0.003155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3684</th>\n",
       "      <td>319</td>\n",
       "      <td>1</td>\n",
       "      <td>gt</td>\n",
       "      <td>0.003135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8713 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ham  Spam       Token  spam_ratio\n",
       "2067    1   114       claim  114.000000\n",
       "6113    1    94       prize   94.000000\n",
       "352     1    72        150p   72.000000\n",
       "7837    1    61        tone   61.000000\n",
       "369     1    52          18   52.000000\n",
       "3688    1    51  guaranteed   51.000000\n",
       "617     1    45         500   45.000000\n",
       "2371    1    45          cs   45.000000\n",
       "299     1    42        1000   42.000000\n",
       "1333    1    39     awarded   39.000000\n",
       "8016    2    75          uk   37.500000\n",
       "356     1    35      150ppm   35.000000\n",
       "6525    1    33    ringtone   33.000000\n",
       "8596    3    99         www   33.000000\n",
       "1       1    30         000   30.000000\n",
       "2150    1    27  collection   27.000000\n",
       "2963    1    27       entry   27.000000\n",
       "364     2    54          16   27.000000\n",
       "7838    1    27       tones   27.000000\n",
       "618     1    26        5000   26.000000\n",
       "5117    1    26         mob   26.000000\n",
       "8375    1    25      weekly   25.000000\n",
       "309     1    25         10p   25.000000\n",
       "8153    1    25       valid   25.000000\n",
       "732     1    23         800   23.000000\n",
       "5297    1    23    national   23.000000\n",
       "1623    1    22       bonus   22.000000\n",
       "735     1    22        8007   22.000000\n",
       "6619    1    22         sae   22.000000\n",
       "8248    1    22    vouchers   22.000000\n",
       "...   ...   ...         ...         ...\n",
       "3925  166     3        home    0.018072\n",
       "2815   56     1         dun    0.017857\n",
       "5533  115     2          oh    0.017391\n",
       "5217  116     2        much    0.017241\n",
       "5254  755    13          my    0.017219\n",
       "1064   59     1      always    0.016949\n",
       "7001   59     1       sleep    0.016949\n",
       "3595   59     1       gonna    0.016949\n",
       "3171   63     1        feel    0.015873\n",
       "8394   63     1        went    0.015873\n",
       "5371   63     1        nice    0.015873\n",
       "3690   68     1         gud    0.014706\n",
       "7099   70     1   something    0.014286\n",
       "7463   72     1        sure    0.013889\n",
       "4724   75     1         lol    0.013333\n",
       "1142   77     1    anything    0.012987\n",
       "2289   77     1         cos    0.012987\n",
       "2163  231     3        come    0.012987\n",
       "5167   80     1     morning    0.012500\n",
       "2714   89     1       doing    0.011236\n",
       "1084   89     1         amp    0.011236\n",
       "1247   90     1         ask    0.011111\n",
       "6626   90     1        said    0.011111\n",
       "4550  136     1       later    0.007353\n",
       "2428  151     1          da    0.006623\n",
       "4747  163     1         lor    0.006135\n",
       "6843  168     1         she    0.005952\n",
       "3805  232     1          he    0.004310\n",
       "4793  317     1          lt    0.003155\n",
       "3684  319     1          gt    0.003135\n",
       "\n",
       "[8713 rows x 4 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counts.sort(['spam_ratio'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('WINNER!! As a valued network customer you have been selected to receivea \\xc2\\xa3900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.', '\\n')\n",
      "('Urgent UR awarded a complimentary trip to EuroDisinc Trav, Aco&Entry41 Or \\xc2\\xa31000. To claim txt DIS to 87121 18+6*\\xc2\\xa31.50(moreFrmMob. ShrAcomOrSglSuplt)10, LS1 3AJ', '\\n')\n",
      "('You are a winner U have been specially selected 2 receive \\xc2\\xa31000 or a 4* holiday (flights inc) speak to a live operator 2 claim 0871277810910p/min (18+) ', '\\n')\n",
      "('PRIVATE! Your 2004 Account Statement for 07742676969 shows 786 unredeemed Bonus Points. To claim call 08719180248 Identifier Code: 45239 Expires', '\\n')\n",
      "('Todays Voda numbers ending 7548 are selected to receive a $350 award. If you have a match please call 08712300220 quoting claim code 4041 standard rates app', '\\n')\n"
     ]
    }
   ],
   "source": [
    "#observe spam messages that contain the word 'claim'\n",
    "claim_messages = sms.message[sms.message.str.contains('claim')]\n",
    "\n",
    "for message in claim_messages[0:5]:\n",
    "    print(message, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Building a Naive Bayes model\n",
    "\n",
    "We will use [Multinomial Naive Bayes](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html):\n",
    "\n",
    "> The multinomial Naive Bayes classifier is suitable for classification with **discrete features** (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train_dtm\n",
    "X_test = X_test_dtm\n",
    "y_train = y_train\n",
    "y_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a Naive Bayes model using X_train_dtm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "nb = MultinomialNB()\n",
    "\n",
    "nb.fit(X_train,y_train)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "preds = nb.predict(X_test)\n",
    "preds_lr = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB:  0.988513998564\n",
      "LR:  0.987796123475\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,roc_auc_score\n",
    "\n",
    "print \"NB: \",accuracy_score(y_test,preds)\n",
    "print \"LR: \",accuracy_score(y_test,preds_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1203,    5],\n",
       "       [  11,  174]], dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "confusion_matrix(y_test,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict (poorly calibrated) probabilities\n",
    "preds_prob = nb.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.97122551e-01,   2.87744864e-03],\n",
       "       [  9.99981651e-01,   1.83488846e-05],\n",
       "       [  9.97926987e-01,   2.07301295e-03],\n",
       "       ..., \n",
       "       [  9.99998910e-01,   1.09026171e-06],\n",
       "       [  1.86697467e-10,   1.00000000e+00],\n",
       "       [  9.99999996e-01,   3.98279868e-09]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98664310005369615"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate AUC\n",
    "roc_auc_score(y_test,preds_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "574               Waiting for your call.\n",
       "3375             Also andros ice etc etc\n",
       "45      No calls..messages..missed calls\n",
       "3415             No pic. Please re-send.\n",
       "1988    No calls..messages..missed calls\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print message text for the false positives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1078                         Yep, by the pretty sculpture\n",
       "4028        Yes, princess. Are you going to make me moan?\n",
       "958                            Welp apparently he retired\n",
       "4642                                              Havent.\n",
       "4674    I forgot 2 ask ü all smth.. There's a card on ...\n",
       "5461    Ok i thk i got it. Then u wan me 2 come now or...\n",
       "4210    I want kfc its Tuesday. Only buy 2 meals ONLY ...\n",
       "4216                           No dear i was sleeping :-P\n",
       "1603                            Ok pa. Nothing problem:-)\n",
       "1504                      Ill be there on  &lt;#&gt;  ok.\n",
       "1783    My uncles in Atlanta. Wish you guys a great se...\n",
       "3465                                             My phone\n",
       "5534                         Ok which your another number\n",
       "4267    The greatest test of courage on earth is to be...\n",
       "2498    Dai what this da.. Can i send my resume to thi...\n",
       "4259                        I am late. I will be there at\n",
       "147     FreeMsg Why haven't you replied to my text? I'...\n",
       "141                     K, text me when you're on the way\n",
       "4517    Congrats! 2 mobile 3G Videophones R yours. cal...\n",
       "3053    Please leave this topic..sorry for telling that..\n",
       "5392    Ooooooh I forgot to tell u I can get on yovill...\n",
       "2346            Hi this is yijue, can i meet u at 11 tmr?\n",
       "1242    I want to show you the world, princess :) how ...\n",
       "3224                    Well that must be a pain to catch\n",
       "4872                  Well. You know what i mean. Texting\n",
       "3044           Your bill at 3 is £33.65 so thats not bad!\n",
       "1660                         Yeah, where's your class at?\n",
       "3214                                       What's ur pin?\n",
       "501     Fighting with the world is easy, u either win ...\n",
       "1827    Dude. What's up. How Teresa. Hope you have bee...\n",
       "                              ...                        \n",
       "2285                              Velly good, yes please!\n",
       "4829    Lol no. Just trying to make your day a little ...\n",
       "2155    Oh god i am happy to see your message after 3 ...\n",
       "3555                       am up to my eyes in philosophy\n",
       "4582    Not course. Only maths one day one chapter wit...\n",
       "1010    Dear Hero,i am leaving to qatar tonite for an ...\n",
       "2007    Shopping lor. Them raining mah hard 2 leave or...\n",
       "221                             Ok no prob. Take ur time.\n",
       "1961    Guess what! Somebody you know secretly fancies...\n",
       "1141            Oh:)as usual vijay film or its different?\n",
       "2270                               Haha i think i did too\n",
       "2589    My superior telling that friday is leave for a...\n",
       "3779    Once a fishrman woke early in d mrng. It was v...\n",
       "1714    Hard LIVE 121 chat just 60p/min. Choose your g...\n",
       "1463    09066362231 URGENT! Your mobile No 07xxxxxxxxx...\n",
       "2694    All these nice new shirts and the only thing I...\n",
       "1925                                                   Ok\n",
       "3597               Good morning princess! Happy New Year!\n",
       "1988                     No calls..messages..missed calls\n",
       "932     Congratulations ore mo owo re wa. Enjoy it and...\n",
       "2870    House-Maid is the murderer, coz the man was mu...\n",
       "5458                               Sorry, I'll call later\n",
       "2890                               My battery is low babe\n",
       "3658             Studying. But i.ll be free next weekend.\n",
       "4285    Yes. I come to nyc for audiitions and am tryin...\n",
       "3207                                        At home also.\n",
       "4655                     Hope you are having a great day.\n",
       "1140    Message:some text missing* Sender:Name Missing...\n",
       "1793    WIN: We have a winner! Mr. T. Foley won an iPo...\n",
       "1710    U meet other fren dun wan meet me ah... Muz b ...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_a, X_test_a, y_train_a, y_test_a = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({\"Message\":X_test_a,\"Actual\":y_test_a,\"Pred\":preds,\"Pred Prob\":preds_prob[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Message</th>\n",
       "      <th>Pred</th>\n",
       "      <th>Pred Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>0</td>\n",
       "      <td>Waiting for your call.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.648309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3375</th>\n",
       "      <td>0</td>\n",
       "      <td>Also andros ice etc etc</td>\n",
       "      <td>1</td>\n",
       "      <td>0.561037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>No calls..messages..missed calls</td>\n",
       "      <td>1</td>\n",
       "      <td>0.697142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3415</th>\n",
       "      <td>0</td>\n",
       "      <td>No pic. Please re-send.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.552917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>0</td>\n",
       "      <td>No calls..messages..missed calls</td>\n",
       "      <td>1</td>\n",
       "      <td>0.697142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual                           Message  Pred  Pred Prob\n",
       "574        0            Waiting for your call.     1   0.648309\n",
       "3375       0           Also andros ice etc etc     1   0.561037\n",
       "45         0  No calls..messages..missed calls     1   0.697142\n",
       "3415       0           No pic. Please re-send.     1   0.552917\n",
       "1988       0  No calls..messages..missed calls     1   0.697142"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print message text for the false negatives\n",
    "pred_df[(pred_df.Actual == 0) & (pred_df.Pred == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Would you like to see my XXX pics they are so hot they were nearly banned in the uk!'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.Message[1875]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"LookAtMe!: Thanks for your purchase of a video clip from LookAtMe!, you've been charged 35p. Think you can do better? Why not send a video in a MMSto 32323.\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what do you notice about the false negatives?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(max_df=0.8,min_df=0.2)\n",
    "\n",
    "X_train = vect.fit_transform(X_train_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vect.transform(X_test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86719310839913855"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb2 = MultinomialNB()\n",
    "nb2.fit(X_train,y_train)\n",
    "preds2 = nb2.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,preds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Comparing Naive Bayes with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a logitic regression\n",
    "# import/instantiate/fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class predictions and predicted probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate accuracy and AUC\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
